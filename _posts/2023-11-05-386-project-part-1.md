---
layout: post
title:  "Project Part 1 - Idea and Data Gathering"
author: Connor Thompson
description: How you can utilize cutting edge AI as a virtual assistant to write a blog.
image: "/assets/images/football_image.jpg"
---

## The Question
On the evening of October 21, 2023, I was watching the football game between Texas Tech and BYU.  It was not a very close game, with BYU up by 17 points at the half.  As I was sitting and waiting during the thirty minutes of halftime, a question occurred to me.  I love watching BYU play, but was it worth staying when we were up by so much?  Was there even a chance for Texas Tech to come back?  If so, how probable was it?
That is the motivation of the question for this project.  How accurately can you predict the final score of a game at halftime?  What about after the first quarter, or the third quarter?  After you have that prediction, is it even worth staying for the rest of the game, or is the probability of a given outcome so high that you might as well leave?  In this project, I will attempt to answer these questions.

## The Data
In order to even begin this project, I knew I would need a lot of data.  All of the code can be found at my <a href="https://github.com/csthomps/s386-project" target="_blank">github repo</a>. 
I started looking for good sources to get the specific data I would need.  At a very basic level, I needed the points scored in each quarter, for each game I could find.  After a bit of searching, I found a treasure trove on <a href="https://www.cbssports.com/" target="_blank">CBS Sport's Site</a>.  Specifically, <a href="https://www.cbssports.com/college-football/scoreboard/FBS/2023/regular/10/" target="_blank">this page</a>, which has exactly what I needed as far as quarter scores.  Because of the organization of the site and the urls, I was easily able to scrape all the data I wanted from the 2017-2022 seasons.  
However, that main page didn't have everything I wanted.  I realized that another important data point would be who started the game with the ball, and therefore who would be starting with the ball in the second half.  This was a bit harder to get, and significantly increased the time it takes for the scraping to run.  In order to get it, I had to go to the play by play page of each game on the site (here is <a href="https://www.cbssports.com/college-football/gametracker/playbyplay/NCAAF_20231104_UL@ARKST/" target="_blank">an example</a>).  Unfortunately, not every game has an associated play by play page, so I had to check and make sure it even existed first.
After spending so much time on those two parts, I realized that there was another data point I wanted.  CBS has rankings for teams listed with each game, but I realized that those rankings only show the rank of the team at the end of the season, not the rank they had at the time of a given game.  I knew that if I wanted to be able to accurately model the outcomes of games, I would need to know (or estimate) the strength of the teams involved.  Take this example:  say a game is tied at halftime.  It would be quite difficult to predict who will win, as it would probably be close to a 50-50 shot for either team.  Of course, it would depend on things like home-team advantage and who is starting with the ball in the second half, but even with those it would be imprecise.  However, if I had an estimate of the strengths of the teams the model would have much more information.
I looked far and wide, and could not find the data I wanted for this anywhere on the internet.  So, I resolved myself to calculating it myself.  After speaking to a professor at BYU (many thanks to Dr. Sandholtz), I found <a href="http://www.glicko.net/research/nfl-chapter.pdf" target="_blank">this paper</a> by Mark Glickman and Hal Stern.  By following some of their methods, I was able to estimate the predicted outcome of a game based purely on the team's performances in previous games in the dataset.  While there are several weaknesses to this model, which I may attempt to overcome in the future, it gave me a good enough estimate for my purposes.  I went through every game in the dataset and calculated both the expected probability that the home team would win, and the predicted score differential (home team score - away team score).

## Ethical Considerations
It is very important when web scraping to make sure that you are scraping ethically.  Some sites specifically disallow scraping on their website, or only disallow in on certain parts of the site.  As of writing this, CBS has <a href="https://www.cbssports.com/robots.txt" target="_blank">no restrictions</a> on scraping the /college-football/ portion of their site.  As such, it is perfectly fine for me to scrape the data there.  The only other ethical consideration so far is using Glickman and Stern's methods to predict the game outcomes, but their paper is publically published and I made sure to give them due credit.

## Final Words
I am very happy with the data I was able to gather for this project.  While the data scraping and processing script takes several hours to run, I am excited with the potential it has for modeling and prediction.  There is a lot of interesting work to do with it, and I will keep posting about it on this blog as I continue the project.